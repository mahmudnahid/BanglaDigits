{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy.fftpack import dct\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n",
    "import os\n",
    "import re\n",
    "from numpy import newaxis\n",
    "from script import *\n",
    "fol_input= 'data'\n",
    "#rootdir='enter_directory/bengali/'\n",
    "fol_output ='output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data,y=extract_features(rootdir,fol_output)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4630.3955</td>\n",
       "      <td>0.375</td>\n",
       "      <td>21.351954</td>\n",
       "      <td>-0.719815</td>\n",
       "      <td>-8.196278</td>\n",
       "      <td>26.936718</td>\n",
       "      <td>-19.449858</td>\n",
       "      <td>-17.036129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212878</td>\n",
       "      <td>-1.243805</td>\n",
       "      <td>-1.012372</td>\n",
       "      <td>-1.102883</td>\n",
       "      <td>0.859878</td>\n",
       "      <td>-0.084953</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>-0.182059</td>\n",
       "      <td>0.441208</td>\n",
       "      <td>-0.898221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2461.6045</td>\n",
       "      <td>0.375</td>\n",
       "      <td>20.098391</td>\n",
       "      <td>1.551649</td>\n",
       "      <td>1.592873</td>\n",
       "      <td>16.977976</td>\n",
       "      <td>-19.883131</td>\n",
       "      <td>0.615746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246557</td>\n",
       "      <td>-1.505821</td>\n",
       "      <td>-0.049629</td>\n",
       "      <td>-0.571831</td>\n",
       "      <td>0.283111</td>\n",
       "      <td>0.730313</td>\n",
       "      <td>-0.113071</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.156661</td>\n",
       "      <td>-0.418779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250</td>\n",
       "      <td>149.0</td>\n",
       "      <td>3584.3870</td>\n",
       "      <td>0.250</td>\n",
       "      <td>20.956120</td>\n",
       "      <td>-2.268425</td>\n",
       "      <td>1.146147</td>\n",
       "      <td>14.091915</td>\n",
       "      <td>-29.660058</td>\n",
       "      <td>5.689657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132114</td>\n",
       "      <td>-2.483086</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>-0.980473</td>\n",
       "      <td>0.130590</td>\n",
       "      <td>1.044733</td>\n",
       "      <td>0.541760</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.086317</td>\n",
       "      <td>-0.478497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2808.2725</td>\n",
       "      <td>0.250</td>\n",
       "      <td>20.332793</td>\n",
       "      <td>-8.685330</td>\n",
       "      <td>-1.751928</td>\n",
       "      <td>2.360482</td>\n",
       "      <td>-21.104983</td>\n",
       "      <td>-15.582627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.713040</td>\n",
       "      <td>-2.114468</td>\n",
       "      <td>-1.112978</td>\n",
       "      <td>-0.756730</td>\n",
       "      <td>1.572786</td>\n",
       "      <td>-0.702936</td>\n",
       "      <td>1.092423</td>\n",
       "      <td>-0.651345</td>\n",
       "      <td>0.369725</td>\n",
       "      <td>-1.030937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.375</td>\n",
       "      <td>218.0</td>\n",
       "      <td>5847.5745</td>\n",
       "      <td>0.375</td>\n",
       "      <td>21.062612</td>\n",
       "      <td>4.713172</td>\n",
       "      <td>-4.133764</td>\n",
       "      <td>21.734452</td>\n",
       "      <td>-21.487389</td>\n",
       "      <td>-14.077373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085253</td>\n",
       "      <td>-0.646281</td>\n",
       "      <td>-0.677582</td>\n",
       "      <td>-0.464765</td>\n",
       "      <td>0.664453</td>\n",
       "      <td>-0.224184</td>\n",
       "      <td>0.943724</td>\n",
       "      <td>-0.437191</td>\n",
       "      <td>0.420615</td>\n",
       "      <td>-0.517588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.625</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3088.1430</td>\n",
       "      <td>0.625</td>\n",
       "      <td>21.830339</td>\n",
       "      <td>9.826351</td>\n",
       "      <td>10.550861</td>\n",
       "      <td>17.904464</td>\n",
       "      <td>17.368982</td>\n",
       "      <td>13.733715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166994</td>\n",
       "      <td>-0.160295</td>\n",
       "      <td>-0.086541</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>-0.028367</td>\n",
       "      <td>-0.117457</td>\n",
       "      <td>-0.220260</td>\n",
       "      <td>-0.140531</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>-0.150371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4914.3295</td>\n",
       "      <td>0.375</td>\n",
       "      <td>22.482414</td>\n",
       "      <td>-3.667647</td>\n",
       "      <td>10.320054</td>\n",
       "      <td>16.501035</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-12.272070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>-0.136798</td>\n",
       "      <td>-0.346180</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>-0.205358</td>\n",
       "      <td>-0.020771</td>\n",
       "      <td>0.035203</td>\n",
       "      <td>-0.078086</td>\n",
       "      <td>-0.342679</td>\n",
       "      <td>0.298173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.375</td>\n",
       "      <td>161.0</td>\n",
       "      <td>7095.3445</td>\n",
       "      <td>0.375</td>\n",
       "      <td>21.256248</td>\n",
       "      <td>5.459345</td>\n",
       "      <td>19.091223</td>\n",
       "      <td>34.818831</td>\n",
       "      <td>8.351679</td>\n",
       "      <td>-3.461627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492791</td>\n",
       "      <td>-0.659160</td>\n",
       "      <td>-1.078929</td>\n",
       "      <td>-0.096979</td>\n",
       "      <td>-0.172090</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>-0.630295</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>-0.412699</td>\n",
       "      <td>-0.075829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.375</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5718.6200</td>\n",
       "      <td>0.375</td>\n",
       "      <td>22.381089</td>\n",
       "      <td>5.495798</td>\n",
       "      <td>13.439258</td>\n",
       "      <td>35.754372</td>\n",
       "      <td>9.829241</td>\n",
       "      <td>-2.309807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481407</td>\n",
       "      <td>0.194590</td>\n",
       "      <td>-0.331913</td>\n",
       "      <td>0.099226</td>\n",
       "      <td>-0.589532</td>\n",
       "      <td>-0.573803</td>\n",
       "      <td>0.113955</td>\n",
       "      <td>-0.704119</td>\n",
       "      <td>-0.609228</td>\n",
       "      <td>-0.230985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1          2      3          4         5          6          7   \\\n",
       "1  0.375  220.0  4630.3955  0.375  21.351954 -0.719815  -8.196278  26.936718   \n",
       "2  0.375  233.0  2461.6045  0.375  20.098391  1.551649   1.592873  16.977976   \n",
       "3  0.250  149.0  3584.3870  0.250  20.956120 -2.268425   1.146147  14.091915   \n",
       "4  0.250  137.0  2808.2725  0.250  20.332793 -8.685330  -1.751928   2.360482   \n",
       "5  0.375  218.0  5847.5745  0.375  21.062612  4.713172  -4.133764  21.734452   \n",
       "6  0.625   97.0  3088.1430  0.625  21.830339  9.826351  10.550861  17.904464   \n",
       "7  0.375  272.0  4914.3295  0.375  22.482414 -3.667647  10.320054  16.501035   \n",
       "8  0.375  161.0  7095.3445  0.375  21.256248  5.459345  19.091223  34.818831   \n",
       "9  0.375  112.0  5718.6200  0.375  22.381089  5.495798  13.439258  35.754372   \n",
       "\n",
       "          8          9     ...           59        60        61        62  \\\n",
       "1 -19.449858 -17.036129    ...    -0.212878 -1.243805 -1.012372 -1.102883   \n",
       "2 -19.883131   0.615746    ...     0.246557 -1.505821 -0.049629 -0.571831   \n",
       "3 -29.660058   5.689657    ...     0.132114 -2.483086  0.116573 -0.980473   \n",
       "4 -21.104983 -15.582627    ...    -0.713040 -2.114468 -1.112978 -0.756730   \n",
       "5 -21.487389 -14.077373    ...    -0.085253 -0.646281 -0.677582 -0.464765   \n",
       "6  17.368982  13.733715    ...    -0.166994 -0.160295 -0.086541  0.075274   \n",
       "7   0.145729 -12.272070    ...     0.052838 -0.136798 -0.346180  0.002503   \n",
       "8   8.351679  -3.461627    ...     0.492791 -0.659160 -1.078929 -0.096979   \n",
       "9   9.829241  -2.309807    ...     0.481407  0.194590 -0.331913  0.099226   \n",
       "\n",
       "         63        64        65        66        67        68  \n",
       "1  0.859878 -0.084953  0.164384 -0.182059  0.441208 -0.898221  \n",
       "2  0.283111  0.730313 -0.113071  0.000293 -0.156661 -0.418779  \n",
       "3  0.130590  1.044733  0.541760 -0.063003 -0.086317 -0.478497  \n",
       "4  1.572786 -0.702936  1.092423 -0.651345  0.369725 -1.030937  \n",
       "5  0.664453 -0.224184  0.943724 -0.437191  0.420615 -0.517588  \n",
       "6 -0.028367 -0.117457 -0.220260 -0.140531  0.052672 -0.150371  \n",
       "7 -0.205358 -0.020771  0.035203 -0.078086 -0.342679  0.298173  \n",
       "8 -0.172090  0.034703 -0.630295  0.539300 -0.412699 -0.075829  \n",
       "9 -0.589532 -0.573803  0.113955 -0.704119 -0.609228 -0.230985  \n",
       "\n",
       "[9 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#from numpy import newaxis\n",
    "X_train=np.array(data[0:8000])\n",
    "X_train=X_train[...,newaxis]\n",
    "\n",
    "y_train=np.array(y[0:8000])\n",
    "\n",
    "X_test=np.array(data[8000:10000])\n",
    "\n",
    "X_test=X_test[...,newaxis]\n",
    "y_test=np.array(y[8000:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194 204 195 172 196 230 163 203 201 242]\n",
      "[774 837 783 762 788 846 732 796 803 879]\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(y_test)\n",
    "print np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "hidden_units = 100\n",
    "nb_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000L, 69L, 1L)\n",
      "(8000L, 10L)\n",
      "(69L, 1L)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "\n",
    "print X_train.shape[1:]\n",
    "print nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', \n",
    "               activation='tanh', \n",
    "               inner_activation='sigmoid', \n",
    "               input_shape=X_train.shape[1:]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 84s - loss: 2.2402 - acc: 0.1320 - val_loss: 2.1215 - val_acc: 0.1980\n",
      "Epoch 2/30\n",
      "8000/8000 [==============================] - 91s - loss: 1.9644 - acc: 0.2138 - val_loss: 1.9685 - val_acc: 0.2260\n",
      "Epoch 3/30\n",
      "8000/8000 [==============================] - 92s - loss: 1.8451 - acc: 0.2724 - val_loss: 1.8633 - val_acc: 0.2920\n",
      "Epoch 4/30\n",
      "8000/8000 [==============================] - 75s - loss: 1.6793 - acc: 0.3720 - val_loss: 1.6886 - val_acc: 0.3700\n",
      "Epoch 5/30\n",
      "8000/8000 [==============================] - 89s - loss: 1.5138 - acc: 0.4476 - val_loss: 1.5742 - val_acc: 0.4460\n",
      "Epoch 6/30\n",
      "8000/8000 [==============================] - 75s - loss: 1.4049 - acc: 0.4963 - val_loss: 1.3251 - val_acc: 0.5470\n",
      "Epoch 7/30\n",
      "8000/8000 [==============================] - 78s - loss: 1.3055 - acc: 0.5309 - val_loss: 1.2020 - val_acc: 0.5755\n",
      "Epoch 8/30\n",
      "8000/8000 [==============================] - 76s - loss: 1.2100 - acc: 0.5814 - val_loss: 1.0538 - val_acc: 0.6500\n",
      "Epoch 9/30\n",
      "8000/8000 [==============================] - 78s - loss: 1.1089 - acc: 0.6079 - val_loss: 0.9987 - val_acc: 0.6580\n",
      "Epoch 10/30\n",
      "8000/8000 [==============================] - 84s - loss: 1.0428 - acc: 0.6469 - val_loss: 0.8445 - val_acc: 0.7115\n",
      "Epoch 11/30\n",
      "8000/8000 [==============================] - 101s - loss: 0.9701 - acc: 0.6678 - val_loss: 0.7413 - val_acc: 0.7510\n",
      "Epoch 12/30\n",
      "8000/8000 [==============================] - 95s - loss: 0.8989 - acc: 0.6981 - val_loss: 0.6329 - val_acc: 0.7920\n",
      "Epoch 13/30\n",
      "8000/8000 [==============================] - 87s - loss: 0.8503 - acc: 0.7135 - val_loss: 0.6810 - val_acc: 0.7955\n",
      "Epoch 14/30\n",
      "8000/8000 [==============================] - 82s - loss: 0.8030 - acc: 0.7368 - val_loss: 0.5402 - val_acc: 0.8370\n",
      "Epoch 15/30\n",
      "8000/8000 [==============================] - 95s - loss: 0.7532 - acc: 0.7581 - val_loss: 0.4670 - val_acc: 0.8620\n",
      "Epoch 16/30\n",
      "8000/8000 [==============================] - 88s - loss: 0.7120 - acc: 0.7705 - val_loss: 0.4528 - val_acc: 0.8690\n",
      "Epoch 17/30\n",
      "8000/8000 [==============================] - 85s - loss: 0.6782 - acc: 0.7804 - val_loss: 0.4151 - val_acc: 0.8860\n",
      "Epoch 18/30\n",
      "8000/8000 [==============================] - 77s - loss: 0.6598 - acc: 0.7860 - val_loss: 0.3845 - val_acc: 0.8930\n",
      "Epoch 19/30\n",
      "8000/8000 [==============================] - 77s - loss: 0.6074 - acc: 0.8068 - val_loss: 0.3462 - val_acc: 0.8980\n",
      "Epoch 20/30\n",
      "8000/8000 [==============================] - 80s - loss: 0.5927 - acc: 0.8086 - val_loss: 0.4223 - val_acc: 0.8750\n",
      "Epoch 21/30\n",
      "8000/8000 [==============================] - 81s - loss: 0.5638 - acc: 0.8214 - val_loss: 0.2913 - val_acc: 0.9190\n",
      "Epoch 22/30\n",
      "8000/8000 [==============================] - 81s - loss: 0.5418 - acc: 0.8268 - val_loss: 0.2963 - val_acc: 0.9225\n",
      "Epoch 23/30\n",
      "8000/8000 [==============================] - 86s - loss: 0.5216 - acc: 0.8309 - val_loss: 0.3141 - val_acc: 0.9055\n",
      "Epoch 24/30\n",
      "8000/8000 [==============================] - 86s - loss: 0.4825 - acc: 0.8485 - val_loss: 0.2476 - val_acc: 0.9335\n",
      "Epoch 25/30\n",
      "8000/8000 [==============================] - 81s - loss: 0.4687 - acc: 0.8504 - val_loss: 0.2550 - val_acc: 0.9275\n",
      "Epoch 26/30\n",
      "8000/8000 [==============================] - 100s - loss: 0.4676 - acc: 0.8530 - val_loss: 0.4577 - val_acc: 0.8515\n",
      "Epoch 27/30\n",
      "8000/8000 [==============================] - 88s - loss: 0.4553 - acc: 0.8549 - val_loss: 0.3064 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "8000/8000 [==============================] - 104s - loss: 0.4313 - acc: 0.8639 - val_loss: 0.2398 - val_acc: 0.9260\n",
      "Epoch 29/30\n",
      "8000/8000 [==============================] - 103s - loss: 0.4161 - acc: 0.8689 - val_loss: 0.2487 - val_acc: 0.9285\n",
      "Epoch 30/30\n",
      "8000/8000 [==============================] - 100s - loss: 0.4160 - acc: 0.8724 - val_loss: 0.2762 - val_acc: 0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda2\\lib\\site-packages\\keras\\models.py:610: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c71b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=30, validation_data=(X_test, Y_test), show_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 7s     \n",
      "0.917000004165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda2\\lib\\site-packages\\keras\\models.py:651: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test.astype(numpy.float32, copy=False), Y_test.astype(numpy.float32, copy=False),\n",
    "                            batch_size=batch_size,\n",
    "                            show_accuracy=True)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Y_pred=model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
